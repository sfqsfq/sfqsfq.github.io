[{"categories":["Kubernetes"],"content":" PV æ˜¯å¯¹åº•å±‚ç½‘ç»œå…±äº«å­˜å‚¨çš„æŠ½è±¡ PVC æ˜¯å¯¹ PV çš„è¯·æ±‚ StorageClassä½œä¸ºå¯¹å­˜å‚¨èµ„æºçš„æŠ½è±¡å®šä¹‰ï¼Œå¯¹ç”¨æˆ·è®¾ç½®çš„PVCç”³è¯·å±è”½åç«¯å­˜å‚¨çš„ç»†èŠ‚ï¼Œä¸€æ–¹é¢å‡å°‘äº†ç”¨æˆ·å¯¹äºå­˜å‚¨èµ„æºç»†èŠ‚çš„å…³æ³¨ï¼Œå¦ä¸€æ–¹é¢å‡è½»äº†ç®¡ç†å‘˜æ‰‹å·¥ç®¡ç†PVçš„å·¥ä½œï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å®ŒæˆPVçš„åˆ›å»ºå’Œç»‘å®šï¼Œå®ç°äº†åŠ¨æ€çš„èµ„æºä¾›åº”ã€‚ CSI æ˜¯ Container Storage Interface çš„ç¼©å†™ï¼Œæ˜¯ä¸€ä¸ªè§„èŒƒï¼Œç”¨äºå®šä¹‰å­˜å‚¨æ’ä»¶ä¸ Kubernetes ä¹‹é—´çš„æ¥å£ PV 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: v1 # PV kind: PersistentVolume metadata: name: pv1 spec: # å­˜å‚¨å®¹é‡ capacity: storage: 1Gi # å­˜å‚¨å·æ¨¡å¼ volumeMode: Filesystem # è®¿é—®æ¨¡å¼ accessModes: - ReadWriteOnce # å›æ”¶ç­–ç•¥ persistentVolumeReclaimPolicy: Recycle # å­˜å‚¨ç±»å‹ storageClassName: slow # å­˜å‚¨ä½ç½® nfs: path: /data/pv1 server: node3.sfq.me PVC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion: v1 # PVC kind: PersistentVolumeClaim metadata: name: pvc1 spec: # èµ„æºè¯·æ±‚ resources: requests: storage: 1Gi # è®¿é—®æ¨¡å¼ accessModes: - ReadWriteOnce # å­˜å‚¨å·æ¨¡å¼ # volumeMode: Filesystem # å­˜å‚¨ç±»å‹ storageClassName: slow # PV çš„é€‰æ‹©æ¡ä»¶ selector: matchLabels: release: \"stable\" matchExpressions: - {key: environment, operator: In, values: [dev]} StorageClass 1 2 3 4 5 6 7 8 9 10 11 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow # æä¾›è€…ï¼Œä»¥ kubernetes.io/ å¼€å¤´ provisioner: kubernetes.io/nfs # å‚æ•° parameters: server: \"node3.sfq.me\" share: \"/data/pv\" mountOptions: \"vers=4.1\" åŠ¨æ€èµ„æºä¾›åº”æ¨¡å¼ 1. å®šä¹‰ storageClass å‚è€ƒ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 sfqfs@sfq:~/k8s/storageClass$ helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ nfs.ser\u003e --set nfs.server=node3.sfq.me \\ \u003e --set nfs.path=/data/pv NAME: nfs-subdir-external-provisioner LAST DEPLOYED: Fri Mar 17 00:38:06 2023 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None sfqfs@sfq:~/k8s/storageClass$ kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE local-path (default) rancher.io/local-path Delete WaitForFirstConsumer false 10d nfs-client cluster.local/nfs-subdir-external-provisioner Delete Immediate true 2m48s 2. å®šä¹‰ PVC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: v1 # PVC kind: PersistentVolumeClaim metadata: name: pvc1 spec: # èµ„æºè¯·æ±‚ resources: requests: storage: 1Gi # è®¿é—®æ¨¡å¼ accessModes: - ReadWriteOnce # å­˜å‚¨å·æ¨¡å¼ # volumeMode: Filesystem # å­˜å‚¨ç±»å‹ storageClassName: nfs-client 3. Podä½¿ç”¨ PVC çš„å­˜å‚¨èµ„æº 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: v1 kind: Pod metadata: name: pod-test-pv spec: containers: - name: pod-test-pv image: busybox command: - sh - -c - sleep 36000 volumeMounts: - name: mypvc mountPath: /mnt/data volumes: - name: mypvc persistentVolumeClaim: claimName: pvc1 4. æµ‹è¯• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # å½“å‰ pv sfqfs@sfq:~/k8s/storageClass$ kubectl get pv No resources found # åˆ›å»º pvc sfqfs@sfq:~/k8s/storageClass$ kubectl create -f pvc.yaml persistentvolumeclaim/pvc1 created sfqfs@sfq:~/k8s/storageClass$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE pvc1 Bound pvc-74c60ca7-9e55-4a5d-8e1b-1d7e84ad72ba 1Gi RWO nfs-client 2s # æŸ¥çœ‹ pv sfqfs@sfq:~/k8s/storageClass$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-74c60ca7-9e55-4a5d-8e1b-1d7e84ad72ba 1Gi RWO Delete Bound default/pvc1 nfs-client 15s # åˆ›å»º pod sfqfs@sfq:~/k8s/storageClass$ kubectl create -f pod.yaml pod/pod-test-pv created sfqfs@sfq:~/k8s/storageClass$ kubectl exec -it pod/pod-test-pv -- ls /mnt/data/ aa.txt sfqfs@sfq:~/k8s/storageClass$ ssh sfq@node3.sfq.me ls /data/pv default-pvc1-pvc-74c60ca7-9e55-4a5d-8e1b-1d7e84ad72ba sfqfs@sfq:~/k8s/storageClass$ ssh sfq@node3.sfq.me ls /data/pv/default-pvc1-pvc-74c60ca7-9e55-4a5d-8e1b-1d7e84ad72ba aa.txt é™æ€èµ„æºä¾›åº”æ¨¡å¼ 1. æ‰‹åŠ¨åˆ›å»º PV 1 2 3 4 5 6 7 8 9 10 11 12 kind: PersistentVolume apiVersion: v1 metadata: name: pv-sfq-nfs spec: capacity: storage: 10Gi accessModes: - ReadWriteMany nfs: server: node3.sfq.me path: /data/nfs 2. åˆ›å»º PVC 1 2 3 4 5 6 7 8 9 10 11 12 13 kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-sfq-nfs spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi # é™æ€å­˜å‚¨ç®¡ç† storageClassName ä¸ºç©º storageClassName: \"\" volumeName: pv-sfq-nfs 3. Pod ä½¿ç”¨ PVC çš„å­˜å‚¨èµ„æº 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: v1 kind: Pod metadata: name: pod-sfq-pvc spec: containers: - name: pod-sfq-pvc image: busybox command: - sh - -c - sleep 36000 volumeMounts: - name: mypvc mountPath: /mnt/data volumes: - name: mypvc persistentVolumeClaim: claimName: pvc-sfq-nfs 4. æµ‹è¯• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # pv åˆ›å»º sfqfs@sfq:~/k8s/storageClass/static$ kubectl create -f pv.yml persistentvolume/pv-sfq-nfs created sfqfs@sfq:~/k8s/storageClass/static$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-681662da-ec58-471c-be39-5dd17ffa1a53 1Gi RWO Delete Bound default/pvc1 nfs-client 10h pv-sfq-nfs 10Gi RWX Retain Available 3s # pvc åˆ›å»º sfqfs@sfq:~/k8s/storageClass/static$ kubectl create -f pvc.yaml persistentvolumeclaim/pvc-sfq-nfs created sfqfs@sfq:~/k8s/storageClass/static$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE pvc1 Bound pvc-681662da-ec58-471c-be39-5dd17ffa1a53 1Gi RWO nfs-client 10h pvc-sfq-nfs Bound pv-sfq-nfs 10Gi RWX 2s # pod ä½¿ç”¨ pvc sfqfs@sfq:~/k8s/storageClass/static$ kubectl get pod -w NAME READY STATUS RESTARTS AGE nginx-deployment-7bf89ffbcd-d29qq 1/1 Running 0 11d nginx-deployment-7bf89ffbcd-5s6sm 1/1 Running 0 10d nfs-subdir-external-provisioner-7757cd775b-hskkp 1/1 Running 0 10h pod-test-pv 1/1 Running 1 (12m ago) 10h pod-sfq-pvc 1/1 Running 0 4s # æµ‹è¯• sfqfs@sfq:~/k8s/storageClass/static$ kubectl exec -it pod-sfq-pvc -- touch /mnt/data/test sfqfs@sfq:~/k8s/storageClass/static$ ssh sfq@node3.sfq.me ls -l /data/nfs/ total 0 -rw-r--r--. 1 root root 0 Mar 16 23:16 test ","description":"","tags":["Kubernetes","PV","PVC"],"title":"K8S PV PVC","uri":"/posts/k8s-pv-pvc/"},{"categories":["Kubernetes"],"content":"éœ€è¦æŒä¹…åŒ–æ•°æ®çš„ç¨‹åºä¼šç”¨åˆ° Volumesã€‚\næ—¥å¿—æ”¶é›†éœ€æ±‚ï¼Œåœ¨åº”ç”¨ç¨‹åºçš„å®¹å™¨é‡Œé¢åŠ ä¸€ä¸ª sidecar, é€šè¿‡å…±äº«å·çš„æ–¹å¼ï¼Œå°†æ—¥å¿—æ”¶é›†åˆ° sidecar å®¹å™¨é‡Œé¢ï¼Œå†é€šè¿‡ sidecar å®¹å™¨å°†æ—¥å¿—æ”¶é›†åˆ°å¤–éƒ¨çš„æ—¥å¿—æ”¶é›†ç³»ç»Ÿã€‚ hostPath hostPath æ˜¯æœ€ç®€å•çš„ Volume ç±»å‹ï¼Œå®ƒç›´æ¥å°† Pod çš„ Volume æŒ‚è½½åˆ°å®¿ä¸»æœºçš„ç›®å½•ä¸Šã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # åˆ›å»º Pod èµ„æºå¯¹è±¡ sfqfs@sfq:~$ cat\u003c\u003cEOF | kubectl create -f - # pod-hostpath.yaml apiVersion: v1 kind: Pod metadata: name: pod-hostpath spec: containers: - name: busybox image: busybox command: [\"sh\", \"-c\", \"sleep 36000\"] volumeMounts: - name: tmp mountPath: /test volumes: # å°†å®¿ä¸»çš„ /tmp ç›®å½•æŒ‚è½½åˆ°å®¹å™¨çš„ /test ç›®å½• - name: tmp hostPath: path: /tmp nodeSelector: # æŒ‚è½½åˆ° node4 èŠ‚ç‚¹ä¸Šçš„ç›®å½• node: node4 EOF # åœ¨ Pod ä¸­åˆ›å»ºæ–‡ä»¶ï¼Œåœ¨å®¿ä¸»æœºä¸ŠæŸ¥çœ‹ sfqfs@sfq:~/k8s$ kubectl exec -it pod-hostpath -- touch /test/file-create-in-pod sfqfs@sfq:~/k8s$ ssh sfq@node4.sfq.me ls /tmp file-create-in-pod systemd-private-7f857c3921084bd1ab8676ed07a91071-chronyd.service-8J5JY3 emptyDir emptyDir æ˜¯ä¸€ä¸ªä¸´æ—¶ç›®å½•ï¼Œå½“ Pod è¢«åˆ é™¤æ—¶ï¼ŒemptyDir ä¹Ÿä¼šè¢«åˆ é™¤ã€‚ ç”¨äºå­˜æ”¾ Pod è¿è¡Œæ—¶çš„æ•°æ®ï¼Œæ¯”å¦‚æ—¥å¿—æ–‡ä»¶ï¼Œç”¨äº Pod ä¸­ä¸åŒ Container ä¹‹é—´çš„æ•°æ®å…±äº«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # åˆ›å»º Pod èµ„æºå¯¹è±¡ï¼Œå®¹å™¨ busybox-1 å’Œ busybox-2 å…±äº«ä¸€ä¸ª emptyDir å· # ä¸¤ä¸ªå®¹å™¨éƒ½å¯ä»¥è¯»å†™è¿™ä¸ªå· sfqfs@sfq:~$ cat\u003c\u003cEOF | kubectl create -f - # pod-emptydir.yaml apiVersion: v1 kind: Pod metadata: name: pod-emptydir spec: containers: - name: busybox-1 image: busybox command: [\"sh\", \"-c\", \"sleep 36000\"] volumeMounts: - name: shared mountPath: /test-1 - name: busybox-2 image: busybox command: [\"sh\", \"-c\", \"sleep 36000\"] volumeMounts: - name: shared mountPath: /test-2 volumes: # å…±äº«å· - name: shared emptyDir: {} EOF sfqfs@sfq:~/k8s$ kubectl exec -it pod-emptydir -c busybox-1 -- touch /test-1/file-from-busybox-1 sfqfs@sfq:~/k8s$ kubectl exec -it pod-emptydir -c busybox-2 -- ls /test-2 file-from-busybox-1 NFS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # åˆ›å»º NFS Volume sfqfs@sfq:~$ cat\u003c\u003cEOF | kubectl create -f - # nfs-server.yaml apiVersion: v1 kind: Pod metadata: name: nfs-server spec: containers: - name: pod-nfs-volume image: busybox command: [\"sh\", \"-c\", \"sleep 36000\"] volumeMounts: - name: nfs-volume mountPath: /data volumes: - name: nfs-volume nfs: server: node3.sfq.me path: /data EOF sfqfs@sfq:~/k8s$ kubectl exec -it nfs-server -- df -Th Filesystem Type Size Used Available Use% Mounted on overlay overlay 50.0G 4.8G 45.2G 10% / tmpfs tmpfs 64.0M 0 64.0M 0% /dev tmpfs tmpfs 2.4G 0 2.4G 0% /sys/fs/cgroup node3.sfq.me:/data nfs4 50.0G 4.9G 45.1G 10% /data sfqfs@sfq:~/k8s$ kubectl exec -it nfs-server -- touch /data/file-create-in-pod sfqfs@sfq:~/k8s$ ssh sfq@node3.sfq.me ls /data file-create-in-pod ","description":"","tags":["Kubernetes","Volumes"],"title":"K8S Volumes","uri":"/posts/k8s-volumes/"},{"categories":["Kubernetes"],"content":"ConfigMap ä¾›å®¹å™¨ä½¿ç”¨çš„å…¸å‹ç”¨æ³•\nç”Ÿæˆä¸ºå®¹å™¨å†…çš„ç¯å¢ƒå˜é‡ è®¾ç½®å®¹å™¨å¯åŠ¨å‘½ä»¤çš„å¯åŠ¨å‚æ•°ï¼ˆéœ€è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼‰ ä»¥Volumeçš„å½¢å¼æŒ‚è½½ä¸ºå®¹å™¨å†…éƒ¨çš„æ–‡ä»¶æˆ–ç›®å½• ä½¿ç”¨YAMLæ–‡ä»¶åˆ›å»ºConfigMap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # åˆ›å»º ConfigMap èµ„æºå¯¹è±¡ sfqfs@sfq:~$ cat\u003c\u003cEOF | kubectl create -f - # cm-appvars.yaml apiVersion: v1 kind: ConfigMap metadata: name: cm-appvars data: apploglevel: \"info\" appdatadir: /var/data EOF # è·å– configmap å¯¹è±¡ sfqfs@sfq:~$ kubectl get cm/cm-appvars NAME DATA AGE cm-appvars 2 68s # æ‰“å° configmap çš„è¯¦ç»†ä¿¡æ¯ sfqfs@sfq:~$ kubectl describe cm/cm-appvars Name: cm-appvars Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Data ==== appdatadir: ---- /var/data apploglevel: ---- info BinaryData ==== Events: \u003cnone\u003e å‘½ä»¤è¡Œæ–¹å¼åˆ›å»º 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # å¯ä»¥æŒ‡å®š key, æ²¡æœ‰æŒ‡å®šç›´æ¥ä½¿ç”¨æ–‡ä»¶åä½œä¸ºkey # source å¯ä»¥ä¸ºç›®å½•ï¼Œæ­¤æ—¶æŠŠå½“å‰æ–‡ä»¶jiançš„æ‰€æœ‰æ–‡ä»¶ä½œä¸ºkey, æ–‡ä»¶å†…å®¹ä½œä¸ºvalue kubectl create configmap cm-test1 --from-file=[key=]source --from-file=[key=]source sfqfs@sfq:~/k8s/StatefulSet$ ls busybox.yaml nginx-sts.yaml statefulset.md mongo-headless-service.yaml statefulset-mongo.yaml storageclass-fast.yaml sfqfs@sfq:~/k8s/StatefulSet$ kubectl create configmap cm-files --from-file=. configmap/cm-files created sfqfs@sfq:~/k8s/StatefulSet$ kubectl get cm/cm-files NAME DATA AGE cm-files 6 4s sfqfs@sfq:~/k8s/ingress-nginx$ kubectl create configmap cm-literals --from-literal=key1=value1 configmap/cm-literals created sfqfs@sfq:~/k8s/ingress-nginx$ kubectl describe cm/cm-literals Name: cm-literals Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Data ==== key1: ---- value1 BinaryData ==== Events: \u003cnone\u003e ä½¿ç”¨ env.valueFrom.configMapKeyRef è·å– ConfigMap ä¸­çš„å€¼åˆ°ç¯å¢ƒå˜é‡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 cat\u003c\u003cEOF | kubectl create -f - apiVersion: v1 kind: Pod metadata: name: pod-cm-env spec: restartPolicy: Never containers: - name: cm-test image: busybox command: [\"/bin/sh\", \"-c\", \"env | grep APP\"] env: # å®šä¹‰ç¯å¢ƒå˜é‡åç§° - name: APPLOGLEVEL # å®šä¹‰ç¯å¢ƒå˜é‡å¯¹åº”çš„å€¼ valueFrom: configMapKeyRef: # æŒ‡å®šç¯å¢ƒå˜é‡æ¥è‡ªcm/cm-appvars name: cm-appvars # æŒ‡å®šç¯å¢ƒå˜é‡åœ¨ cm/cm-appvars ä¸­çš„é”® key: apploglevel - name: APPDATADIR valueFrom: configMapKeyRef: name: cm-appvars key: appdatadir EOF sfqfs@sfq:~/k8s$ kubectl logs pod/pod-cm-env APPDATADIR=/var/data APPLOGLEVEL=info xxdsdasdsa adsdsadasdasd sfqfs@sfq:~/k8s$ ä½¿ç”¨ envFrom è·å– ConfigMap ä¸­çš„å€¼åˆ°ç¯å¢ƒå˜é‡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cat\u003c\u003cEOF | kubectl create -f - apiVersion: v1 kind: Pod metadata: name: pod-cm-env spec: restartPolicy: Never containers: - name: cm-test image: busybox command: [\"/bin/sh\", \"-c\", \"env | grep app\"] envFrom: - configMapRef: name: cm-appvars EOF sfqfs@sfq:~/k8s$ kubectl logs pod-cm-env apploglevel=info xxdsdasdsa adsdsadasdasd appdatadir=/var/data ä½¿ç”¨ volumeMount å°† ConfigMap æŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨çš„æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 cat\u003c\u003cEOF | kubectl create -f - apiVersion: v1 kind: Pod metadata: name: pod-cm-env spec: restartPolicy: Never containers: - name: cm-test image: busybox command: [\"/bin/sh\", \"-c\", \"ls /files; cat /files/*\"] volumeMounts: - name: files mountPath: /files volumes: # å®šä¹‰ volume åç§° - name: files configMap: # æŒ‡å®šä½¿ç”¨çš„ configmap å¯¹è±¡ name: cm-appvars # å°† key å¯¹è±¡çš„å€¼ä»¥ path æŒ‡å®šçš„æ–‡ä»¶åè¿›è¡ŒæŒ‚è½½ # å¦‚æœä¸æŒ‡å®š items, åˆ™é»˜è®¤å°†æ‰€æœ‰ key å¯¹è±¡çš„å€¼ä»¥æ–‡ä»¶åçš„å½¢å¼æŒ‚è½½ items: - key: apploglevel path: apploglevel.txt - key: appdatadir path: appdatadir.txt EOF sfqfs@sfq:~/k8s$ kubectl logs pod-cm-env appdatadir.txt apploglevel.txt /var/datainfo xxdsdasdsa adsdsadasdasd ä½¿ç”¨ subPath 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion: v1 kind: Pod metadata: name: pod-cm-env spec: restartPolicy: Never containers: - name: cm-test image: busybox command: [\"/bin/sh\", \"-c\", \"sleep 3600\"] volumeMounts: - name: files mountPath: /etc/apploglevel.txt subPath: apploglevel.txt volumes: # å®šä¹‰ volume åç§° - name: files configMap: # æŒ‡å®šä½¿ç”¨çš„ configmap å¯¹è±¡ name: cm-appvars items: - key: apploglevel path: apploglevel.txt EOF çƒ­æ›´æ–° ConfigMap 1 kubectl create cm cm-nginx --from-file=nginx.conf --dry-run -oyaml | kubectl replace -f - ","description":"","tags":["Kubernetes","ConfigMap","Secret"],"title":"K8S ConfigMap Secret","uri":"/posts/k8s-configmap-secret/"},{"categories":["Kuberneters"],"content":"Ingress ä¹Ÿæ˜¯ k8s çš„èµ„æºç±»å‹ï¼Œingress ç”¨äºå®ç°ç”¨åŸŸåçš„æ–¹å¼è®¿é—® k8s å†…éƒ¨åº”ç”¨.\nChart: Helm åŒ…ï¼ŒåŒ…å«åœ¨ Kubernetes é›†ç¾¤å†…éƒ¨è¿è¡Œåº”ç”¨ç¨‹åºï¼Œå·¥å…·æˆ–è€…æœåŠ¡æ‰€éœ€çš„æ‰€æœ‰èµ„æºå®šä¹‰ã€‚ Repository: ä»“åº“ï¼Œç”¨æ¥å­˜æ”¾å’Œå…±äº« charts çš„åœ°æ–¹ Release: è¿è¡Œåœ¨ k8s é›†ç¾¤ä¸­çš„ chart ç¤ºä¾‹ã€‚ä¸€ä¸ª chart é€šå¸¸å¯ä»¥åœ¨ä¸€ä¸ªé›†ç¾¤ä¸­å®‰è£…å¤šæ¬¡ã€‚æ¯æ¬¡å®‰è£…éƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ releaseã€‚ ingress nginx å®‰è£… 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # å®‰è£…ç¬¬ä¸‰æ–¹ä»“åº“ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx # ä»“åº“æŸ¥çœ‹ sfqfs@sfq:~/k8s$ helm repo list NAME URL ingress-nginx https://kubernetes.github.io/ingress-nginx test https://kubernetes.github.io/ingress-nginx # chart æŸ¥æ‰¾ sfqfs@sfq:~/k8s$ helm search repo ingress-nginx NAME CHART VERSION APP VERSION DESCRIPTION ingress-nginx/ingress-nginx 4.5.2 1.6.4 Ingress controller for Kubernetes using NGINX a... test/ingress-nginx 4.5.2 1.6.4 Ingress controller for Kubernetes using NGINX a... # chart ä¸‹è½½åˆ°æœ¬åœ° sfqfs@sfq:~/k8s$ helm pull ingress-nginx/ingress-nginx sfqfs@sfq:~/k8s$ ls -l ingress-nginx-4.5.2.tgz -rw-r--r-- 1 sfqfs sfqfs 46009 Mar 13 14:01 ingress-nginx-4.5.2.tgz # è§£å‹ sfqfs@sfq:~/k8s$ tar xf ingress-nginx-4.5.2.tgz sfqfs@sfq:~/k8s$ ls ingress-nginx CHANGELOG.md Chart.yaml OWNERS README.md README.md.gotmpl changelog changelog.md.gotmpl ci templates values.yaml sfqfs@sfq:~/k8s$ ä¿®æ”¹ values.yaml\nä¿®æ”¹é•œåƒåœ°å€ï¼ˆimageï¼‰\nhostNetwork: true ï¼ˆä½¿ç”¨ä¸»æœºç½‘ç»œï¼‰\ndnsPolicy: ClusterFirstWithHostNet (å’Œ hostNetwork: true é…åˆä½¿ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨é›†ç¾¤å†…éƒ¨çš„åŸŸåè§£æ)\nä½¿ç”¨ kind: DaemonSet æ–¹å¼éƒ¨ç½²ï¼Œå¯ä»¥å›ºå®šåˆ°æŸäº›èŠ‚ç‚¹ï¼Œå¤–éƒ¨è´Ÿè½½å‡è¡¡å¯ä»¥ç›´æ¥ä»£ç†åˆ°è¿™å‡ å°æœºå™¨ä¸Š\nnodeSelector é…ç½®ä¸€ä¸‹éœ€è¦é€‰æ‹©å“ªäº›èŠ‚ç‚¹\n1 2 3 nodeSelector: kubernetes.io/os: linux ingress: true resource é…ç½®\nservice.type = LoadBalancer æ”¹ä¸º service.type = ClusterIP å› ä¸ºæœ¬èº«å°±æ˜¯é€šè¿‡å®¿ä¸»æœºçš„ IP æ¥è®¿é—®äº†\néƒ¨ç½² ingress\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 sfqfs@sfq:~/k8s/ingress-nginx$ kubectl create ns ingress-nginx namespace/ingress-nginx created sfqfs@sfq:~/k8s/ingress-nginx$ helm install ingress-nginx -n ingress-nginx . NAME: ingress-nginx LAST DEPLOYED: Mon Mar 13 15:48:15 2023 NAMESPACE: ingress-nginx STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export POD_NAME=$(kubectl --namespace ingress-nginx get pods -o jsonpath=\"{.items[0].metadata.name}\" -l \"app=ingress-nginx,component=controller,release=ingress-nginx\") kubectl --namespace ingress-nginx port-forward $POD_NAME 8080:80 echo \"Visit http://127.0.0.1:8080 to access your application.\" An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example namespace: foo spec: ingressClassName: nginx rules: - host: www.example.com http: paths: - pathType: Prefix backend: service: name: exampleService port: number: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u003cbase64 encoded cert\u003e tls.key: \u003cbase64 encoded key\u003e type: kubernetes.io/tls ç»™ä¸€ä¸ªèŠ‚ç‚¹é™„åŠ  ingress=true æ¥è§¦å‘ pod ingress-nginx å®‰è£…\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # æŸ¥çœ‹å½“å‰ pod sfqfs@sfq:~/k8s$ kubectl get pod -A -owide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5cfbb9f57c-l7xh5 1/1 Running 0 7d14h 10.42.0.3 node1.sfq.me \u003cnone\u003e \u003cnone\u003e kube-system local-path-provisioner-5f8bbd68f9-nhwbw 1/1 Running 0 7d14h 10.42.0.2 node1.sfq.me \u003cnone\u003e \u003cnone\u003e default nginx-deployment-7bf89ffbcd-d29qq 1/1 Running 0 7d5h 10.42.4.7 node4.sfq.me \u003cnone\u003e \u003cnone\u003e minio-dev minio 1/1 Running 0 7d 10.42.4.8 node4.sfq.me \u003cnone\u003e \u003cnone\u003e default nginx-deployment-7bf89ffbcd-5s6sm 1/1 Running 0 7d3h 10.42.1.9 node2.sfq.me \u003cnone\u003e \u003cnone\u003e kube-system metrics-server-847dcc659d-9dkrw 1/1 Running 1 (6d21h ago) 7d12h 10.42.1.7 node2.sfq.me \u003cnone\u003e \u003cnone\u003e default busybox 1/1 Running 73 (51m ago) 7d3h 10.42.1.8 node2.sfq.me \u003cnone\u003e \u003cnone\u003e # åœ¨ node4 ä¸Šå®‰è£… ingress-nginx sfqfs@sfq:~/k8s$ kubectl label node node4.sfq.me ingress=true node/node4.sfq.me labeled # æŸ¥çœ‹ ingress-nginx å®‰è£…æˆåŠŸ sfqfs@sfq:~/k8s$ kubectl get pod -A -owide -w NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5cfbb9f57c-l7xh5 1/1 Running 0 7d14h 10.42.0.3 node1.sfq.me \u003cnone\u003e \u003cnone\u003e kube-system local-path-provisioner-5f8bbd68f9-nhwbw 1/1 Running 0 7d14h 10.42.0.2 node1.sfq.me \u003cnone\u003e \u003cnone\u003e default nginx-deployment-7bf89ffbcd-d29qq 1/1 Running 0 7d5h 10.42.4.7 node4.sfq.me \u003cnone\u003e \u003cnone\u003e minio-dev minio 1/1 Running 0 7d 10.42.4.8 node4.sfq.me \u003cnone\u003e \u003cnone\u003e default nginx-deployment-7bf89ffbcd-5s6sm 1/1 Running 0 7d3h 10.42.1.9 node2.sfq.me \u003cnone\u003e \u003cnone\u003e kube-system metrics-server-847dcc659d-9dkrw 1/1 Running 1 (6d21h ago) 7d12h 10.42.1.7 node2.sfq.me \u003cnone\u003e \u003cnone\u003e default busybox 1/1 Running 73 (53m ago) 7d3h 10.42.1.8 node2.sfq.me \u003cnone\u003e \u003cnone\u003e ingress-nginx ingress-nginx-controller-psnvh 0/1 Running 0 16s 10.42.4.10 node4.sfq.me \u003cnone\u003e \u003cnone\u003e ingress-nginx ingress-nginx-controller-psnvh 1/1 Running 0 20s 10.42.4.10 node4.sfq.me \u003cnone\u003e \u003cnone\u003e åœ¨èŠ‚ç‚¹ node4 ä¸Šå¯ä»¥çœ‹åˆ°å®¿ä¸»æœºç›‘å¬çš„ç«¯å£\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [sfq@node4 ~]$ sudo netstat -ltpn | grep -E \"80|443\" [sudo] password for sfq: tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 31687/nginx: master tcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 31687/nginx: master tcp6 0 0 :::80 :::* LISTEN 31687/nginx: master tcp6 0 0 :::8443 :::* LISTEN 31631/nginx-ingress tcp6 0 0 :::443 :::* LISTEN 31687/nginx: master [sfq@node4 ~]$ ps aux | grep nginx root 18630 0.0 0.0 8920 3484 ? Ss Mar09 0:00 nginx: master process nginx -g daemon off; 101 18683 0.0 0.0 9308 1772 ? S Mar09 0:01 nginx: worker process 101 18684 0.0 0.0 9308 1776 ? S Mar09 0:01 nginx: worker process 101 31619 0.0 0.0 200 4 ? Ss 03:59 0:00 /usr/bin/dumb-init -- /nginx-ingress-controller --publish-service=ingress-nginx/ingress-nginx-controller --election-id=ingress-nginx-leader --controller-class=k8s.io/ingress-nginx --ingress-class=nginx --configmap=ingress-nginx/ingress-nginx-controller --validating-webhook=:8443 --validating-webhook-certificate=/usr/local/certificates/cert --validating-webhook-key=/usr/local/certificates/key 101 31631 0.2 0.7 754080 35480 ? Ssl 03:59 0:02 /nginx-ingress-controller --publish-service=ingress-nginx/ingress-nginx-controller --election-id=ingress-nginx-leader --controller-class=k8s.io/ingress-nginx --ingress-class=nginx --configmap=ingress-nginx/ingress-nginx-controller --validating-webhook=:8443 --validating-webhook-certificate=/usr/local/certificates/cert --validating-webhook-key=/usr/local/certificates/key 101 31687 0.0 0.7 146860 35432 ? S 03:59 0:00 nginx: master process /usr/bin/nginx -c /etc/nginx/nginx.conf 101 31692 0.0 0.7 158892 39704 ? Sl 03:59 0:00 nginx: worker process 101 31693 0.0 0.8 158996 40544 ? Sl 03:59 0:00 nginx: worker process 101 31694 0.0 0.5 144804 28456 ? S 03:59 0:00 nginx: cache manager process sfq 32352 0.0 0.0 112812 976 pts/0 S+ 04:16 0:00 grep --color=auto nginx [sfq@node4 ~]$ é…ç½® Nginx\nåˆ›å»º serviceaã€serviceb\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion: v1 kind: Service metadata: name: servicea namespace: ingress-nginx spec: selector: app: servicea ports: - name: http port: 8080 type: ClusterIP --- apiVersion: v1 kind: Service metadata: name: serviceb namespace: ingress-nginx spec: selector: app: serviceb ports: - name: http port: 8080 type: ClusterIP é…ç½® ingress-nginx(servicea.sfq.me, serviceb.sfq.me çš„IPéƒ½é…ç½®åˆ° ingress-nginx pod ä½¿ç”¨ä¸»æœºç½‘ç»œçš„é‚£å°æœºå™¨)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-myservicea namespace: ingress-nginx spec: rules: - host: servicea.sfq.me http: paths: - path: /servicea pathType: Prefix backend: service: name: servicea port: number: 8080 ingressClassName: nginx --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-myserviceb namespace: ingress-nginx spec: rules: - host: serviceb.sfq.me http: paths: - path: /serviceb pathType: Prefix backend: service: name: serviceb port: number: 8080 ingressClassName: nginx æµ‹è¯•\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # è®¿é—® ingress-nginx çš„ pod å¯¹åº”å®¿ä¸»æœº sfqfs@sfq:~/k8s$ kubectl get svc -n ingress-nginx -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR ingress-nginx-controller-admission ClusterIP 10.43.200.115 \u003cnone\u003e 443/TCP 3h37m app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx ingress-nginx-controller ClusterIP 10.43.163.111 \u003cnone\u003e 80/TCP,443/TCP 3h37m app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx servicea ClusterIP 10.43.130.154 \u003cnone\u003e 8080/TCP 12m app=servicea serviceb ClusterIP 10.43.97.133 \u003cnone\u003e 8080/TCP 4m25s app=serviceb,namespace=ingress-nginx # è®¿é—®æœåŠ¡A sfqfs@sfq:~/k8s$ curl -v servicea.sfq.me/servicea * Trying 192.168.0.204:80... * TCP_NODELAY set * Connected to servicea.sfq.me (192.168.0.204) port 80 (#0) \u003e GET /servicea HTTP/1.1 \u003e Host: servicea.sfq.me \u003e User-Agent: curl/7.68.0 \u003e Accept: */* \u003e * Mark bundle as not supporting multiuse \u003c HTTP/1.1 200 OK \u003c Date: Mon, 13 Mar 2023 11:28:53 GMT \u003c Content-Type: application/json; charset=utf-8 \u003c Content-Length: 18 \u003c Connection: keep-alive \u003c * Connection #0 to host servicea.sfq.me left intact {\"message\":\"pong\"} # è®¿é—®æœåŠ¡B sfqfs@sfq:~/k8s$ curl -v serviceb.sfq.me/serviceb * Trying 192.168.0.204:80... * TCP_NODELAY set * Connected to serviceb.sfq.me (192.168.0.204) port 80 (#0) \u003e GET /serviceb HTTP/1.1 \u003e Host: serviceb.sfq.me \u003e User-Agent: curl/7.68.0 \u003e Accept: */* \u003e * Mark bundle as not supporting multiuse \u003c HTTP/1.1 503 Service Temporarily Unavailable \u003c Date: Mon, 13 Mar 2023 11:29:01 GMT \u003c Content-Type: text/html \u003c Content-Length: 190 \u003c Connection: keep-alive \u003c \u003chtml\u003e \u003chead\u003e\u003ctitle\u003e503 Service Temporarily Unavailable\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e \u003ccenter\u003e\u003ch1\u003e503 Service Temporarily Unavailable\u003c/h1\u003e\u003c/center\u003e \u003chr\u003e\u003ccenter\u003enginx\u003c/center\u003e \u003c/body\u003e \u003c/html\u003e * Connection #0 to host serviceb.sfq.me left intact ","description":"","tags":["Kuberneters","Ingress"],"title":"K8s Ingress","uri":"/posts/k8s-ingress/"},{"categories":null,"content":"å·¥ä½œæµåˆ›å»º åˆ›å»º .github/workflows ç›®å½• åœ¨ .github/workflows ç›®å½•ä¸‹åˆ›å»º main.yml æ–‡ä»¶ åœ¨ main.yml æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹å†…å®¹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 name: Github Actions Demo run-name: ${{ github.actor }} is testing out Github Actions on: [push] jobs: Explore-Github-Actions: runs-on: ubuntu-latest steps: - run: echo \"ğŸ‰ The job was automatically triggered by a ${{ github.event_name }} event.\" - run: echo \"ğŸ§ This job is now running on a ${{ runner.os }} server hosted by GitHub!\" - run: echo \"ğŸ” The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\" - name: Check out repository code uses: actions/checkout@v3 - run: echo \"ğŸ’¡ The ${{ github.repository }} repository has been cloned to the runner.\" - run: echo \"ğŸ–¥ï¸ The workflow is now ready to test your code on the runner.\" - name: List files in the repository run: | ls ${{ github.workspace }} - run: echo \"ğŸ This job's status is ${{ job.status }}.\" æäº¤ä»£ç åˆ° github ä»“åº“ ","description":"","tags":null,"title":"Github Action","uri":"/posts/github-action/github-action/"}]